# 🐋 deployment spark cluster on k8s
deployment spark cluster on k8s env.


# 🐋 To check with this project

1. Unified Infrastructure Management
> manage Spark along with other services (e.g., Kafka, Airflow) in a unified cluster, simplifying infrastructure operations.

2. Resource Optimization and Dynamic Scaling
> Spark executors and drivers run as pods that dynamically allocate and release resources based on job execution needs.
Auto-scaling: Kubernetes Horizontal Pod Autoscaler (HPA) or Spark's dynamic allocation automatically scales executor pods up and down.

3. DevOps & CI/CD
> CI/CD my Spark application..

<br>

# 🐋 PoC architecture

<img src="https://github.com/user-attachments/assets/40bab1d2-5992-4cc3-83f7-d3362d6e69ad"></img>